{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Box Office Revenue Predictor\n\n##### *Eilert Skram, Torbjørn Moen, 18.11.2022*","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt\nfrom pathlib import Path\nimport math\nfrom functools import reduce\n\n\nDATA = Path('/kaggle/input/tmdb-box-office-prediction')\nlist(DATA.iterdir())\n\ntrain = pd.read_csv(DATA/'train.csv')\ntest = pd.read_csv(DATA/'test.csv')\nsampleSubmission = pd.read_csv(DATA/'sample_submission.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:23.359245Z","iopub.execute_input":"2022-11-17T11:47:23.359914Z","iopub.status.idle":"2022-11-17T11:47:26.232344Z","shell.execute_reply.started":"2022-11-17T11:47:23.359764Z","shell.execute_reply":"2022-11-17T11:47:26.230802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imports, naming of variables","metadata":{}},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:26.237971Z","iopub.execute_input":"2022-11-17T11:47:26.238405Z","iopub.status.idle":"2022-11-17T11:47:26.276158Z","shell.execute_reply.started":"2022-11-17T11:47:26.238365Z","shell.execute_reply":"2022-11-17T11:47:26.274821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:26.277919Z","iopub.execute_input":"2022-11-17T11:47:26.278883Z","iopub.status.idle":"2022-11-17T11:47:26.325487Z","shell.execute_reply.started":"2022-11-17T11:47:26.278835Z","shell.execute_reply":"2022-11-17T11:47:26.324054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A lot of non-numerical values. Will have to handle. Also see trivial columns, i.e poster path","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:26.328606Z","iopub.execute_input":"2022-11-17T11:47:26.329068Z","iopub.status.idle":"2022-11-17T11:47:26.354498Z","shell.execute_reply.started":"2022-11-17T11:47:26.329030Z","shell.execute_reply":"2022-11-17T11:47:26.352801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.hist(bins=50, figsize=(15, 8))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:26.356308Z","iopub.execute_input":"2022-11-17T11:47:26.356936Z","iopub.status.idle":"2022-11-17T11:47:27.651043Z","shell.execute_reply.started":"2022-11-17T11:47:26.356891Z","shell.execute_reply":"2022-11-17T11:47:27.649719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.plot(kind=\"scatter\", x=\"budget\", y=\"revenue\", grid=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:27.653036Z","iopub.execute_input":"2022-11-17T11:47:27.653446Z","iopub.status.idle":"2022-11-17T11:47:27.961240Z","shell.execute_reply.started":"2022-11-17T11:47:27.653406Z","shell.execute_reply":"2022-11-17T11:47:27.960019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems that if higher budget, likely higher revenue","metadata":{}},{"cell_type":"code","source":"train.plot(kind=\"scatter\", x=\"runtime\", y=\"budget\", grid=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:27.962932Z","iopub.execute_input":"2022-11-17T11:47:27.964087Z","iopub.status.idle":"2022-11-17T11:47:28.258406Z","shell.execute_reply.started":"2022-11-17T11:47:27.964030Z","shell.execute_reply":"2022-11-17T11:47:28.257081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.plot(kind=\"scatter\", x=\"runtime\", y=\"revenue\", grid=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.261780Z","iopub.execute_input":"2022-11-17T11:47:28.262770Z","iopub.status.idle":"2022-11-17T11:47:28.536964Z","shell.execute_reply.started":"2022-11-17T11:47:28.262705Z","shell.execute_reply":"2022-11-17T11:47:28.535806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems most movies are withing 90-150min , over 200 min stricly negative. Guessing this is either due to older movies(not scaled for inflation) or a lot of documentaries","metadata":{}},{"cell_type":"code","source":"train.plot(kind=\"scatter\", x=\"popularity\", y=\"revenue\", grid=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.538425Z","iopub.execute_input":"2022-11-17T11:47:28.539472Z","iopub.status.idle":"2022-11-17T11:47:28.813148Z","shell.execute_reply.started":"2022-11-17T11:47:28.539433Z","shell.execute_reply":"2022-11-17T11:47:28.811860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label","metadata":{}},{"cell_type":"code","source":"train_label = train['revenue'].copy()\ntrain = train.drop('revenue', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.817254Z","iopub.execute_input":"2022-11-17T11:47:28.817636Z","iopub.status.idle":"2022-11-17T11:47:28.826639Z","shell.execute_reply.started":"2022-11-17T11:47:28.817602Z","shell.execute_reply":"2022-11-17T11:47:28.825292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top + genre ","metadata":{}},{"cell_type":"code","source":"largest_movie_companies = [\n    'Warner Bros.',                             # Warner Bros. Entertainment\n    'Universal Pictures',                       # NBCUniversal  \n    'Paramount Pictures',                       # Paramount Global\n    'Twentieth Century Fox Film Corporation',   # Walt Disney Studios\n    'Columbia Pictures',                        # Sony Pictures\n    'Metro-Goldwyn-Mayer (MGM)',                # Amazon\n    'New Line Cinema',                          # Warner Bros. Entertainment\n    'Touchstone Pictures',                      # Walt Disney Studios\n    'Walt Disney Pictures',                     # Walt Disney Studios\n    'Columbia Pictures Corporation',            # Sony Pictures\n    'TriStar Pictures'                          # Sony Pictures\n]\n\ntop5_spoken_languages = [\n    'English',\n    'Français',\n    'Español',\n    'Deutsch',\n    'Pусский'\n]\n\ntop5_original_languages = [\n    'en',\n    'fr',\n    'ru',\n    'es',\n    'hi'\n]\n\ntop5_production_countries = [\n    'United States of America', \n    'United Kingdom',\n    'France',\n    'Germany',\n    'Canada'\n]\n\ngenres = [\n    'Crime',\n    'History',\n    'Family',\n    'Horror',\n    'Thriller',\n    'Foreign',\n    'Fantasy',\n    'Music',\n    'Action',\n    'Romance',\n    'Documentary',\n    'Comedy',\n    'TV Movie',\n    'War',\n    'Animation',\n    'Drama',\n    'Science Fiction',\n    'Western',\n    'Adventure',\n    'Mystery'\n]","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.828649Z","iopub.execute_input":"2022-11-17T11:47:28.829022Z","iopub.status.idle":"2022-11-17T11:47:28.840270Z","shell.execute_reply.started":"2022-11-17T11:47:28.828990Z","shell.execute_reply":"2022-11-17T11:47:28.838939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataprocessing pipeline","metadata":{}},{"cell_type":"code","source":"# failsafe eval\ndef m_eval(x):\n    try:\n        out = eval(x)\n    except:\n        out = {}\n    return out\n\n# uniques\ndef unique_values(dataset, column, value):\n    data = dataset[column]\n    \n    data_values = data.map(lambda x: [d[value] for d in m_eval(x)])\n    unique_values = list(set(reduce(lambda x, y: x + y, data_values, [])))\n    \n    return unique_values, data_values, len(unique_values)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.841770Z","iopub.execute_input":"2022-11-17T11:47:28.843108Z","iopub.status.idle":"2022-11-17T11:47:28.857947Z","shell.execute_reply.started":"2022-11-17T11:47:28.843023Z","shell.execute_reply":"2022-11-17T11:47:28.856835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating a custom encoder, essentially works like a one hot encoder","metadata":{}},{"cell_type":"code","source":"def dictEncode(dataframe, column, key, categories, oneHot=True, destColumn=None):\n    if oneHot == False and destColumn == None:\n        raise Exception('You must have a destination column if oneHot is set to False.')\n    \n    # Inserts new columns into the dataframe\n    # if oneHot then add all categories, else add targetColumn\n    if oneHot:\n        for category in categories:\n            dataframe.insert(len(dataframe.columns), category, 0)\n    else:\n        dataframe.insert(len(dataframe.columns), destColumn, 0)\n\n    # loops through all the rows\n    # if oneHot, then set each respective category to 1, else set targetColumn to 1\n    for index, row in dataframe.iterrows():\n        # reads string of form '{'name':'value'}' to dictionary\n        dictionary = m_eval(row[column])\n        \n        # creates a list of every element of a particular key\n        elements = list(map(lambda x: x[key], dictionary))\n        \n        for element in elements:\n            if element in categories:\n                if oneHot:\n                    dataframe.at[index, element] = 1\n                else:\n                    dataframe.at[index, destColumn] = 1","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.859591Z","iopub.execute_input":"2022-11-17T11:47:28.859964Z","iopub.status.idle":"2022-11-17T11:47:28.872570Z","shell.execute_reply.started":"2022-11-17T11:47:28.859932Z","shell.execute_reply":"2022-11-17T11:47:28.871638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Simple function to replace NaN with 0 and any value with 1. Contain or not = True/False","metadata":{}},{"cell_type":"code","source":"def containOrNot (df, columnName, addedName=''):\n    df[addedName+columnName] = df[columnName].notnull().astype('int')\n    if addedName != '':\n        df.drop(columnName, inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.873827Z","iopub.execute_input":"2022-11-17T11:47:28.874362Z","iopub.status.idle":"2022-11-17T11:47:28.893403Z","shell.execute_reply.started":"2022-11-17T11:47:28.874329Z","shell.execute_reply":"2022-11-17T11:47:28.892042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"function to split date into numeric year, and what quarter movie was released","metadata":{}},{"cell_type":"code","source":"def rdConversion(dataframe):\n    data = dataframe.copy()\n    data['release_date'] = data['release_date'].fillna('01/01/01')\n    data['release_date'] = pd.to_datetime(data['release_date'])\n    data['year'] = data['release_date'].dt.year\n    \n    for i in range(1,5):\n        data.insert(len(data.columns), f'quarter_{i}', 0)\n        \n    for index, row in data.iterrows():\n        quarter = row['release_date'].quarter\n        if 1 <= quarter and quarter <= 4:\n            data.at[index, f'quarter_{quarter}'] = 1\n            \n    \n    return data\n            \n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.894851Z","iopub.execute_input":"2022-11-17T11:47:28.895423Z","iopub.status.idle":"2022-11-17T11:47:28.907674Z","shell.execute_reply.started":"2022-11-17T11:47:28.895390Z","shell.execute_reply":"2022-11-17T11:47:28.906433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Custom transformer:","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass CustomTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        if set(['status','crew','cast','overview','poster_path','imdb_id','title', 'original_title']).issubset(X.columns):\n            X.drop( ['status','crew','cast','overview', 'poster_path', 'imdb_id', 'title', 'original_title'], inplace=True, axis=1)\n            \n        \n        \n        dictEncode(X, 'genres', 'name', genres)\n        dictEncode(X, 'production_countries', 'name', top5_production_countries)\n        dictEncode(X, 'production_companies', 'name', largest_movie_companies, oneHot=False, destColumn='top_movie_companies')\n        dictEncode(X, 'spoken_languages', 'name', top5_spoken_languages, oneHot=False, destColumn='top5_spoken_languages')\n        \n        for org in top5_original_languages:\n            X.insert(len(X.columns), 'org_' + org, 0)\n\n        for index, row in X.iterrows():\n            if row['original_language'] in top5_original_languages:\n                X.at[index, 'org_' + row['original_language']] = 1\n                \n        containOrNot(X, 'homepage','has_')\n        containOrNot(X, 'belongs_to_collection')\n        containOrNot(X, 'tagline', 'has_')\n        containOrNot(X, 'Keywords', 'has_')\n        \n        rdConversion(X)\n        X.drop('release_date', inplace=True, axis=1)\n        X.drop( ['genres','production_countries','production_companies','spoken_languages', 'original_language'], inplace=True, axis=1)\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.908974Z","iopub.execute_input":"2022-11-17T11:47:28.909496Z","iopub.status.idle":"2022-11-17T11:47:28.955425Z","shell.execute_reply.started":"2022-11-17T11:47:28.909463Z","shell.execute_reply":"2022-11-17T11:47:28.954092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- If statement to check if allready dropped.\n- encoding date to year, then splitting into what quarter\n- using the custom encoder to map what genres the movie is in\n- using the containorNot function on homepage, belongs to collection and tagline.\n\nAlot of columns are being dropped in first iteration of the model. At later stage would like to explore more how we could use","metadata":{}},{"cell_type":"markdown","source":"[Source of guide how to do custom transformers](https://www.andrewvillazon.com/custom-scikit-learn-transformers/)","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n\n#test = train[['homepage', 'tagline']]\n#num_attri = list(train[['budget','popularity','runtime']])\n\n#numPipeline= Pipeline([\n#('imputer', SimpleImputer(strategy=\"median\")),\n#('std_scaler', StandardScaler()),\n#])\n\n                  \ncustomPipe = Pipeline(steps=[(\"custom\", CustomTransformer()),('imputer', SimpleImputer(strategy=\"median\")), \n                             ('std_scaler', StandardScaler())])\ncustom_attri = list(train)\n\n\nprocessed = customPipe.fit_transform(train)\n#fullPipeline = ColumnTransformer([(\"num\", numPipeline, num_attri)])\n# ,('std_scaler', StandardScaler())\n#,('imputer', SimpleImputer(strategy=\"median\")),\n#('std_scaler', StandardScaler())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:28.957227Z","iopub.execute_input":"2022-11-17T11:47:28.957905Z","iopub.status.idle":"2022-11-17T11:47:31.156477Z","shell.execute_reply.started":"2022-11-17T11:47:28.957870Z","shell.execute_reply":"2022-11-17T11:47:31.155249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:31.158080Z","iopub.execute_input":"2022-11-17T11:47:31.158579Z","iopub.status.idle":"2022-11-17T11:47:31.522213Z","shell.execute_reply.started":"2022-11-17T11:47:31.158533Z","shell.execute_reply":"2022-11-17T11:47:31.520893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBRegressor()\nxgb.fit(processed, train_label)\ngbr = GradientBoostingRegressor()\ngbr.fit(processed, train_label)\nrfr = RandomForestRegressor()\nrfr.fit(processed, train_label)\ndtr = DecisionTreeRegressor()\ndtr.fit(processed, train_label)\nlr = LinearRegression()\nlr.fit(processed, train_label)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:31.523389Z","iopub.execute_input":"2022-11-17T11:47:31.523928Z","iopub.status.idle":"2022-11-17T11:47:34.880401Z","shell.execute_reply.started":"2022-11-17T11:47:31.523883Z","shell.execute_reply":"2022-11-17T11:47:34.878874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.model_selection import cross_val_score\n\nmms = {\n    \"XGBRegressor\": xgb,\n    \"Gradient Boosting Regressor\": gbr,\n    \"Random Forest Regressor\": rfr,\n    \"Decision Tree Regressor\": dtr,\n    \"Linear Regression\": lr\n}\n\nfor key,value in mms.items():\n    score = cross_val_score(value, processed, train_label, scoring=\"neg_mean_squared_error\", cv=10)\n    rmse_score = np.sqrt(-score)\n    print(key)\n    print('Mean:', rmse_score.mean())\n    print('Standard deviation:',rmse_score.std())\n    print(\"-----------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:47:34.882561Z","iopub.execute_input":"2022-11-17T11:47:34.883470Z","iopub.status.idle":"2022-11-17T11:48:05.520633Z","shell.execute_reply.started":"2022-11-17T11:47:34.883406Z","shell.execute_reply":"2022-11-17T11:48:05.518961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random forest is performing best","metadata":{}},{"cell_type":"markdown","source":"## Param tuning","metadata":{}},{"cell_type":"code","source":"rfr.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:48:05.528693Z","iopub.execute_input":"2022-11-17T11:48:05.533308Z","iopub.status.idle":"2022-11-17T11:48:05.553257Z","shell.execute_reply.started":"2022-11-17T11:48:05.533221Z","shell.execute_reply":"2022-11-17T11:48:05.552061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:48:05.555552Z","iopub.execute_input":"2022-11-17T11:48:05.556452Z","iopub.status.idle":"2022-11-17T11:48:05.572583Z","shell.execute_reply.started":"2022-11-17T11:48:05.556405Z","shell.execute_reply":"2022-11-17T11:48:05.571404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n#Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:48:05.573537Z","iopub.execute_input":"2022-11-17T11:48:05.574107Z","iopub.status.idle":"2022-11-17T11:48:05.589413Z","shell.execute_reply.started":"2022-11-17T11:48:05.574058Z","shell.execute_reply":"2022-11-17T11:48:05.587685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Used is assignmetn 1, [Source](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)","metadata":{}},{"cell_type":"markdown","source":"\n\nrf_random = RandomizedSearchCV(estimator = rfr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nrf_random.fit(processed, train_label)\nbest_random = rf_random.best_estimator_\nscore = cross_val_score(best_random, processed, train_label, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_score = np.sqrt(-score)\nprint(\"Best Random\")\nprint('Mean:', rmse_score.mean())\nprint('Standard deviation:',rmse_score.std())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T10:53:28.507662Z","iopub.execute_input":"2022-11-17T10:53:28.508190Z","iopub.status.idle":"2022-11-17T11:02:52.309497Z","shell.execute_reply.started":"2022-11-17T10:53:28.508145Z","shell.execute_reply":"2022-11-17T11:02:52.308026Z"}}},{"cell_type":"markdown","source":"from scipy.stats import uniform as sp_randFloat\nfrom scipy.stats import randint as sp_randInt\n\nparameters = {\"learning_rate\": sp_randFloat(),\n                  \"subsample\"    : sp_randFloat(),\n                  \"n_estimators\" : sp_randInt(100, 1000),\n                  \"max_depth\"    : sp_randInt(4, 10)\n                 }\ngbr_random = RandomizedSearchCV(estimator=gbr, param_distributions = parameters,\n                               cv = 2, n_iter = 10, n_jobs=-1)\ngbr_random.fit(processed, train_label)\n\nbest_random = gbr_random.best_estimator_\nscore = cross_val_score(best_random, processed, train_label, scoring=\"neg_mean_squared_error\", cv=10)\nrmse_score = np.sqrt(-score)\nprint(\"Best Random\")\nprint('Mean:', rmse_score.mean())\nprint('Standard deviation:',rmse_score.std())","metadata":{"execution":{"iopub.status.busy":"2022-11-17T10:36:15.877261Z","iopub.execute_input":"2022-11-17T10:36:15.877687Z","iopub.status.idle":"2022-11-17T10:36:38.635221Z","shell.execute_reply.started":"2022-11-17T10:36:15.877655Z","shell.execute_reply":"2022-11-17T10:36:38.633728Z"}}},{"cell_type":"code","source":"test_id = test.id\ntest_processed = customPipe.transform(test)\nprediction=rfr.predict(test_processed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\nsubmission = pd.DataFrame({'id': test_id, 'revenue': prediction})\nsubmission = submission[['id', 'revenue']]\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:48:58.882819Z","iopub.execute_input":"2022-11-17T11:48:58.883287Z","iopub.status.idle":"2022-11-17T11:48:58.903974Z","shell.execute_reply.started":"2022-11-17T11:48:58.883248Z","shell.execute_reply":"2022-11-17T11:48:58.902810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving model","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# save the model to disk\nfilename = 'finalized_model.sav'\npickle.dump(rfr, open(filename, 'wb'))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T11:57:31.668811Z","iopub.execute_input":"2022-11-17T11:57:31.669241Z","iopub.status.idle":"2022-11-17T11:57:31.725979Z","shell.execute_reply.started":"2022-11-17T11:57:31.669208Z","shell.execute_reply":"2022-11-17T11:57:31.724473Z"},"trusted":true},"execution_count":null,"outputs":[]}]}